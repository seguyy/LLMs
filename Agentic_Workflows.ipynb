{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22711013",
      "metadata": {
        "id": "22711013"
      },
      "source": [
        "# Agentic Workflows\n",
        "\n",
        "Goal is to build an agentic system that generates a short research report through planning, external tool usage, and feedback integration. The workflow will involve:\n",
        "\n",
        "### Agents\n",
        "\n",
        "* **Planning Agent / Writer**: Creates an outline and coordinates tasks.\n",
        "* **Research Agent**: Gathers external information using tools like Arxiv, Tavily, and Wikipedia.\n",
        "* **Editor Agent**: Reflects on the report and provides suggestions for improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4929dc",
      "metadata": {
        "id": "6d4929dc"
      },
      "source": [
        "\n",
        "### Research Tools\n",
        "\n",
        "By importing `research_tools`, you gain access to several search utilities:\n",
        "\n",
        "- `research_tools.arxiv_search_tool(query)` ‚Üí search academic papers from **arXiv**  \n",
        "\n",
        "  *Example:* `research_tools.arxiv_search_tool(\"neural networks for climate modeling\")`\n",
        "\n",
        "- `research_tools.tavily_search_tool(query)` ‚Üí perform web searches with the **Tavily API**  \n",
        "\n",
        "  *Example:* `research_tools.tavily_search_tool(\"latest trends in sunglasses fashion\")`\n",
        "\n",
        "- `research_tools.wikipedia_search_tool(query)` ‚Üí retrieve summaries from **Wikipedia**  \n",
        "\n",
        "  *Example:* `research_tools.wikipedia_search_tool(\"Ensemble Kalman Filter\")`\n",
        "\n",
        "Run the cell below to make them available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9723175",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 302,
        "tags": [
          "graded"
        ],
        "id": "f9723175"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Imports\n",
        "# =========================\n",
        "\n",
        "# --- Standard library\n",
        "from datetime import datetime\n",
        "import re\n",
        "import json\n",
        "import ast\n",
        "\n",
        "\n",
        "# --- Third-party ---\n",
        "from IPython.display import Markdown, display\n",
        "from aisuite import Client\n",
        "\n",
        "# --- Local / project ---\n",
        "import research_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccf88f8b",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 30,
        "id": "ccf88f8b"
      },
      "outputs": [],
      "source": [
        "import unittests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9abc8d9c",
      "metadata": {
        "id": "9abc8d9c"
      },
      "source": [
        "### Initialize client\n",
        "\n",
        "Create a shared client instance for upcoming calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e42f388",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 30,
        "tags": [
          "graded"
        ],
        "id": "2e42f388"
      },
      "outputs": [],
      "source": [
        "CLIENT = Client()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89313f5",
      "metadata": {
        "id": "b89313f5"
      },
      "source": [
        "## Exercise 1: planner_agent\n",
        "\n",
        "### Objective\n",
        "Correctly set up a call to a language model (LLM) to generate a research plan.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. **Focus Areas**:\n",
        "   - Ensure `CLIENT.chat.completions.create` is correctly configured.\n",
        "   - Pass the `model` and `messages` parameters correctly:\n",
        "     - **Model**: Use `\"openai:o4-mini\"` by default.\n",
        "     - **Messages**: Set with `{\"role\": \"user\", \"content\": user_prompt}`.\n",
        "     - **Temperature**: Fixed at 1 for creative outputs.\n",
        "\n",
        "### Notes\n",
        "\n",
        "- The prompt is pre-defined and guides the LLM on task requirements.\n",
        "- Only return a formatted list of steps ‚Äî no extra text.\n",
        "\n",
        "Focus on the LLM call setup to complete the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1add0d",
      "metadata": {
        "deletable": false,
        "height": 1033,
        "tags": [
          "graded"
        ],
        "id": "be1add0d"
      },
      "outputs": [],
      "source": [
        "# planner_agent\n",
        "\n",
        "def planner_agent(topic: str, model: str = \"openai:o4-mini\") -> list[str]:\n",
        "    \"\"\"\n",
        "    Generates a plan as a Python list of steps (strings) for a research workflow.\n",
        "\n",
        "    Args:\n",
        "        topic (str): Research topic to investigate.\n",
        "        model (str): Language model to use.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of executable step strings.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Build the user prompt\n",
        "    user_prompt = f\"\"\"\n",
        "    You are a planning agent responsible for organizing a research workflow with multiple intelligent agents.\n",
        "\n",
        "    üß† Available agents:\n",
        "    - A research agent who can search the web, Wikipedia, and arXiv.\n",
        "    - A writer agent who can draft research summaries.\n",
        "    - An editor agent who can reflect and revise the drafts.\n",
        "\n",
        "    üéØ Your job is to write a clear, step-by-step research plan **as a valid Python list**, where each step is a string.\n",
        "    Each step should be atomic, executable, and must rely only on the capabilities of the above agents.\n",
        "\n",
        "    üö´ DO NOT include irrelevant tasks like \"create CSV\", \"set up a repo\", \"install packages\", etc.\n",
        "    ‚úÖ DO include real research-related tasks (e.g., search, summarize, draft, revise).\n",
        "    ‚úÖ DO assume tool use is available.\n",
        "    ‚úÖ DO NOT include explanation text ‚Äî return ONLY the Python list.\n",
        "    ‚úÖ The final step should be to generate a Markdown document containing the complete research report.\n",
        "\n",
        "    Topic: \"{topic}\"\n",
        "    \"\"\"\n",
        "\n",
        "    # Add the user prompt to the messages list\n",
        "    messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
        "\n",
        "\n",
        "    # Call the LLM\n",
        "    response = CLIENT.chat.completions.create(\n",
        "        # Pass in the model\n",
        "        model=model,\n",
        "        # Define the messages. Remember this is meant to be a user prompt!\n",
        "        messages=messages,\n",
        "        # Keep responses creative\n",
        "        temperature=1,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Extract message from response\n",
        "    steps_str = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Parse steps\n",
        "    steps = ast.literal_eval(steps_str)\n",
        "\n",
        "    return steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aede74d5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 47,
        "id": "aede74d5",
        "outputId": "11421730-3a5c-4601-e55b-6e7a5150701d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# Test your code!\n",
        "unittests.test_planner_agent(planner_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14588d4c",
      "metadata": {
        "id": "14588d4c"
      },
      "source": [
        "## Exercise 2: research_agent\n",
        "\n",
        "### Objective\n",
        "Set up a call to a language model (LLM) to perform a research task using various tools.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "**Focus Areas**:\n",
        "\n",
        "- **Creating a Custom Prompt**:\n",
        "  - **Define the Role**: Clearly specify the role, such as \"research assistant.\"\n",
        "  - **List Available Tools** (as strings inside the prompt, not the actual functions):\n",
        "    - Use `arxiv_tool` to find academic papers.\n",
        "    - Use `tavily_tool` for general web searches.\n",
        "    - Use `wikipedia_tool` for accessing encyclopedic knowledge.\n",
        "  - **Specify the Task**: Include a placeholder in your prompt for defining the specific task that needs to be accomplished.\n",
        "  - **Include Date Information**: Add a placeholder for the current date or time to provide context.\n",
        "\n",
        "- **Creating Messages Dict**:\n",
        "  - Ensure the `messages` are correctly set with `{\"role\": \"user\", \"content\": prompt}`.\n",
        "\n",
        "- **Creating Tools List**:\n",
        "  - Create a list of tools for use, such as `research_tools.arxiv_search_tool`, `research_tools.tavily_search_tool`, and `research_tools.wikipedia_search_tool`.\n",
        "\n",
        "- **Correctly Setting the Call to the LLM**:\n",
        "  - Pass the `model`, `messages`, and `tools` parameters accurately.\n",
        "  - Set `tool_choice` to `\"auto\"` for automatic tool selection.\n",
        "  - Limit interactions with `max_turns=6`.\n",
        "\n",
        "### Notes\n",
        "\n",
        "- The function provides pre-coded blocks where you need to replace placeholder values.\n",
        "- The approach allows the LLM to use tools dynamically based on the task.\n",
        "\n",
        "Focus on accurately setting the messages, tools, and LLM call parameters to complete the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f11f86e",
      "metadata": {
        "deletable": false,
        "height": 1135,
        "tags": [
          "graded"
        ],
        "id": "4f11f86e"
      },
      "outputs": [],
      "source": [
        "# research_agent\n",
        "\n",
        "def research_agent(task: str, model: str = \"openai:gpt-4o\", return_messages: bool = False):\n",
        "    \"\"\"\n",
        "    Executes a research task using tools via aisuite (no manual loop).\n",
        "    Returns either the assistant text, or (text, messages) if return_messages=True.\n",
        "    \"\"\"\n",
        "    print(\"==================================\")\n",
        "    print(\"üîç Research Agent\")\n",
        "    print(\"==================================\")\n",
        "\n",
        "    current_time = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "    # Create a customizable prompt by defining the role (e.g., \"research assistant\"),\n",
        "    # listing tools (arxiv_tool, tavily_tool, wikipedia_tool) for various searches,\n",
        "    # specifying the task with a placeholder, and including a current_time placeholder.\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    You are a research assistant that will gather external information using tools like Arxiv, Tavily, and Wikipedia.\n",
        "\n",
        "    Your goal:\n",
        "    1. Examine the task {task} to accomplish.\n",
        "    2. Go through the list of tools available to perform the task.\n",
        "    3. Once your analysis is done, provide your findings for task {task} and\n",
        "    include also the current date or time {current_time} to provide context.\n",
        "\n",
        "\n",
        "    Tools that are available for you to perform the search:\n",
        "    - arxiv_tool: To find academic papers.\n",
        "    - tavily_tool: To do general web searches.\n",
        "    - wikipedia_tool: To access encyclopedic knowledge.\n",
        "\n",
        "    DO NOT forget to include references where you gather the information from your research!\n",
        "\n",
        "    \"\"\"\n",
        "    # Create the messages dict to pass to the LLM. Remember this is a user prompt!\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Save all of your available tools in the tools list. These can be found in the research_tools module.\n",
        "    # You can identify each tool in your list like this:\n",
        "    # research_tools.<name_of_tool>, where <name_of_tool> is replaced with the function name of the tool.\n",
        "    tools = []\n",
        "\n",
        "    # Call the model with tools enabled\n",
        "    response = CLIENT.chat.completions.create(\n",
        "        # Set the model\n",
        "        model=model,\n",
        "        # Pass in the messages. You already defined this!\n",
        "        messages=messages,\n",
        "        # Pass in the tools list. You already defined this!\n",
        "        tools=tools,\n",
        "        # Set the LLM to automatically choose the tools\n",
        "        tool_choice=\"auto\",\n",
        "        # Set the max turns to 6\n",
        "        max_turns=6\n",
        "    )\n",
        "\n",
        "\n",
        "    content = response.choices[0].message.content\n",
        "    print(\"‚úÖ Output:\\n\", content)\n",
        "\n",
        "\n",
        "    return (content, messages) if return_messages else content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c9a0ce",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 47,
        "id": "a2c9a0ce",
        "outputId": "1041f53c-787c-44be-a183-a598f14cc406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\n",
            "üîç Research Agent\n",
            "==================================\n",
            "‚úÖ Output:\n",
            " To find three key references and summarize them, I will utilize the Arxiv tool for academic papers, the Tavily tool for general web searches, and the Wikipedia tool for encyclopedic knowledge. \n",
            "\n",
            "Let's move forward with using these tools to gather the necessary information in parallel.\n",
            "```json\n",
            "{\n",
            "  \"tool_uses\": [\n",
            "    {\n",
            "      \"recipient_name\": \"functions.arxiv_tool\",\n",
            "      \"parameters\": {\n",
            "        \"query\": \"Key References in AI Research\",\n",
            "        \"max_results\": 3\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"recipient_name\": \"functions.tavily_tool\",\n",
            "      \"parameters\": {\n",
            "        \"query\": \"important AI advancements\",\n",
            "        \"max_results\": 3\n",
            "      }\n",
            "    },\n",
            "    {\n",
            "      \"recipient_name\": \"functions.wikipedia_tool\",\n",
            "      \"parameters\": {\n",
            "        \"query\": \"History of Artificial Intelligence\"\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n",
            "==================================\n",
            "üîç Research Agent\n",
            "==================================\n",
            "‚úÖ Output:\n",
            " To accomplish the task of briefly summarizing two seminal papers, I will utilize the available tools: arxiv_tool to search for academic papers, and tavily_tool for additional background information if needed.\n",
            "\n",
            "I will summarize the papers based on available abstracts and information from the repositories.\n",
            "\n",
            "Given that only the ability to use parallel tools is provided, I will set the plan as follows:\n",
            "\n",
            "1. Use the `arxiv_tool` to find and summarize two seminal academic papers, one in computer science and one in physics.\n",
            "2. Possibly supplement the information from these papers with general web searches using the `tavily_tool` if deeper insights or additional context are required.\n",
            "\n",
            "Here is the approach outlined using the tools:\n",
            "\n",
            "- Search for seminal computer science paper on Arxiv.\n",
            "- Search for seminal physics paper on Arxiv.\n",
            "\n",
            "Let's execute these tasks to gather the relevant summaries and references.\n",
            "Do you have any particular seminal papers in mind, or should I proceed with identifying and summarizing seminal papers based on their citation impact or historical significance?\n",
            "\u001b[92m All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# Test your code!\n",
        "unittests.test_research_agent(research_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9313fa83",
      "metadata": {
        "id": "9313fa83"
      },
      "source": [
        "## Exercise 3: writer_agent\n",
        "\n",
        "### Objective\n",
        "Set up a call to a language model (LLM) for executing writing tasks like drafting, expanding, or summarizing text.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. **Focus Areas**:\n",
        "   - **System Prompt**:\n",
        "     - Define `system_prompt` to assign the LLM the role of a writing agent focused on generating academic or technical content.\n",
        "   - **System and User Messages**:\n",
        "     - Create `system_msg` using `{\"role\": \"system\", \"content\": system_prompt}`.\n",
        "     - Create `user_msg` using `{\"role\": \"user\", \"content\": task}`.\n",
        "   - **Messages List**:\n",
        "     - Combine `system_msg` and `user_msg` into a `messages` list.\n",
        "\n",
        "### Notes\n",
        "\n",
        "- The function is designed to produce well-structured text by setting the correct prompts.\n",
        "- Temperature is set to 1.0 to allow for creative variance in the writing outputs.\n",
        "\n",
        "Ensure the system prompt and messages are defined properly to achieve a structured output from the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b34a6d",
      "metadata": {
        "deletable": false,
        "height": 608,
        "tags": [
          "graded"
        ],
        "id": "57b34a6d"
      },
      "outputs": [],
      "source": [
        "# writer_agent\n",
        "def writer_agent(task: str, model: str = \"openai:gpt-4o\") -> str:\n",
        "    \"\"\"\n",
        "    Executes writing tasks, such as drafting, expanding, or summarizing text.\n",
        "    \"\"\"\n",
        "    print(\"==================================\")\n",
        "    print(\"‚úçÔ∏è Writer Agent\")\n",
        "    print(\"==================================\")\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Create the system prompt.\n",
        "    # This should assign the LLM the role of a writing agent specialized in generating well-structured academic or technical content\n",
        "    system_prompt = \"\"\"\n",
        "    You are a writing agent focused on generating academic or technical content.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the system msg by using the system_prompt and assigning the role of system\n",
        "    system_msg = {\"role\": \"system\" , \"content\": system_prompt}\n",
        "\n",
        "    # Define the user msg. In this case the user prompt should be the task passed to the function\n",
        "    user_msg = {\"role\": \"user\" , \"content\": task}\n",
        "\n",
        "    # Add both system and user messages to the messages list\n",
        "    messages = [system_msg, user_msg]\n",
        "\n",
        "    response = CLIENT.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=1.0\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac93f22d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 47,
        "id": "ac93f22d",
        "outputId": "35a7dca5-55cb-4c54-a526-8a99c1f2c0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\n",
            "‚úçÔ∏è Writer Agent\n",
            "==================================\n",
            "\u001b[92m All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# Test your code!\n",
        "unittests.test_writer_agent(writer_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6918fa15",
      "metadata": {
        "id": "6918fa15"
      },
      "source": [
        "## Editor_agent\n",
        "\n",
        "### Objective\n",
        "Configure a call to a language model (LLM) to perform editorial tasks such as reflecting, critiquing, or revising drafts.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. **Focus Areas**:\n",
        "   - **System Prompt**:\n",
        "     - Define `system_prompt` to assign the LLM the role of an editor agent whose task is to reflect on, critique, or improve drafts.\n",
        "   - **System and User Messages**:\n",
        "     - Create `system_msg` using `{\"role\": \"system\", \"content\": system_prompt}`.\n",
        "     - Create `user_msg` using `{\"role\": \"user\", \"content\": task}`.\n",
        "   - **Messages List**:\n",
        "     - Combine `system_msg` and `user_msg` into a `messages` list.\n",
        "\n",
        "### Notes\n",
        "\n",
        "- The editor agent is tailored for enhancing the quality of text by setting an appropriate role and task in the prompts.\n",
        "- Temperature is set to 0.7, balancing creativity and coherence in editorial outputs.\n",
        "\n",
        "Ensure the system prompt and messages are accurately set up to perform effective editorial tasks with the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f5f4928",
      "metadata": {
        "deletable": false,
        "height": 574,
        "tags": [
          "graded"
        ],
        "id": "3f5f4928"
      },
      "outputs": [],
      "source": [
        "# editor_agent\n",
        "def editor_agent(task: str, model: str = \"openai:gpt-4o\") -> str:\n",
        "    \"\"\"\n",
        "    Executes editorial tasks such as reflection, critique, or revision.\n",
        "    \"\"\"\n",
        "    print(\"==================================\")\n",
        "    print(\"üß† Editor Agent\")\n",
        "    print(\"==================================\")\n",
        "\n",
        "\n",
        "    # Create the system prompt.\n",
        "    # This should assign the LLM the role of an editor agent specialized in reflecting on, critiquing, or improving existing drafts.\n",
        "    system_prompt = f\"\"\"\n",
        "            You are an editor agent, specialized in reflecting on, critiquing, or improving existing drafts.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the system msg by using the system_prompt and assigning the role of system\n",
        "    system_msg = {\"role\": \"system\" , \"content\": system_prompt}\n",
        "\n",
        "    # Define the user msg. In this case the user prompt should be the task passed to the function\n",
        "    user_msg = {\"role\": \"user\" , \"content\": task}\n",
        "\n",
        "    # Add both system and user messages to the messages list\n",
        "    messages = [system_msg, user_msg]\n",
        "\n",
        "\n",
        "    response = CLIENT.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6096f973",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 47,
        "id": "6096f973",
        "outputId": "54531457-5372-495a-975a-52d03acbfb5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\n",
            "üß† Editor Agent\n",
            "==================================\n",
            "\u001b[92m All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# Test your code!\n",
        "unittests.test_editor_agent(editor_agent)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8c98b1e",
      "metadata": {
        "id": "c8c98b1e"
      },
      "source": [
        "### üéØ The Executor Agent\n",
        "\n",
        "The `executor_agent` manages the workflow by executing each step of a given plan. It:\n",
        "\n",
        "1. Decides **which agent** (`research_agent`, `writer_agent`, or `editor_agent`) should handle the step.\n",
        "2. Builds context from the outputs of previous steps.\n",
        "3. Sends the enriched task to the selected agent.\n",
        "4. Collects and stores the results in a shared history.\n",
        "\n",
        "üëâ **Do not implement or modify this function.** It is already provided as the orchestration component of the multi-agent pipeline.\n",
        "\n",
        "Notice that `planner_agent` might return a long list of steps. Because of this, the maximum number of steps is set to a maximum of 4 to keep running time reasonable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf2d02e9",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 268,
        "id": "cf2d02e9"
      },
      "outputs": [],
      "source": [
        "agent_registry = {\n",
        "    \"research_agent\": research_agent,\n",
        "    \"editor_agent\": editor_agent,\n",
        "    \"writer_agent\": writer_agent,\n",
        "}\n",
        "\n",
        "def clean_json_block(raw: str) -> str:\n",
        "    \"\"\"\n",
        "    Clean the contents of a JSON block that may come wrapped with Markdown backticks.\n",
        "    \"\"\"\n",
        "    raw = raw.strip()\n",
        "    if raw.startswith(\"```\"):\n",
        "        raw = re.sub(r\"^```(?:json)?\\n?\", \"\", raw)\n",
        "        raw = re.sub(r\"\\n?```$\", \"\", raw)\n",
        "    return raw.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c41493df",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 1169,
        "id": "c41493df"
      },
      "outputs": [],
      "source": [
        "def executor_agent(topic, model: str = \"openai:gpt-4o\", limit_steps: bool = True):\n",
        "\n",
        "    plan_steps = planner_agent(topic)\n",
        "    max_steps = 4\n",
        "\n",
        "    if limit_steps:\n",
        "        plan_steps = plan_steps[:min(len(plan_steps), max_steps)]\n",
        "\n",
        "    history = []\n",
        "\n",
        "    print(\"==================================\")\n",
        "    print(\"üéØ Editor Agent\")\n",
        "    print(\"==================================\")\n",
        "\n",
        "    for i, step in enumerate(plan_steps):\n",
        "\n",
        "        agent_decision_prompt = f\"\"\"\n",
        "        You are an execution manager for a multi-agent research team.\n",
        "\n",
        "        Given the following instruction, identify which agent should perform it and extract the clean task.\n",
        "\n",
        "        Return only a valid JSON object with two keys:\n",
        "        - \"agent\": one of [\"research_agent\", \"editor_agent\", \"writer_agent\"]\n",
        "        - \"task\": a string with the instruction that the agent should follow\n",
        "\n",
        "        Only respond with a valid JSON object. Do not include explanations or markdown formatting.\n",
        "\n",
        "        Instruction: \"{step}\"\n",
        "        \"\"\"\n",
        "        response = CLIENT.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": agent_decision_prompt}],\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "        raw_content = response.choices[0].message.content\n",
        "        cleaned_json = clean_json_block(raw_content)\n",
        "        agent_info = json.loads(cleaned_json)\n",
        "\n",
        "        agent_name = agent_info[\"agent\"]\n",
        "        task = agent_info[\"task\"]\n",
        "\n",
        "        context = \"\\n\".join([\n",
        "            f\"Step {j+1} executed by {a}:\\n{r}\"\n",
        "            for j, (s, a, r) in enumerate(history)\n",
        "        ])\n",
        "        enriched_task = f\"\"\"\n",
        "        You are {agent_name}.\n",
        "\n",
        "        Here is the context of what has been done so far:\n",
        "        {context}\n",
        "\n",
        "        Your next task is:\n",
        "        {task}\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"\\nüõ†Ô∏è Executing with agent: `{agent_name}` on task: {task}\")\n",
        "\n",
        "        if agent_name in agent_registry:\n",
        "            output = agent_registry[agent_name](enriched_task)\n",
        "            history.append((step, agent_name, output))\n",
        "        else:\n",
        "            output = f\"‚ö†Ô∏è Unknown agent: {agent_name}\"\n",
        "            history.append((step, agent_name, output))\n",
        "\n",
        "        print(f\"‚úÖ Output:\\n{output}\")\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "086f00f8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "height": 115,
        "id": "086f00f8",
        "outputId": "b1fe34d4-63a5-48ae-b482-2d38c95ae9f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\n",
            "üéØ Editor Agent\n",
            "==================================\n",
            "\n",
            "üõ†Ô∏è Executing with agent: `research_agent` on task: Search Wikipedia and textbooks for fundamental definitions and the mathematical formulation of the ensemble Kalman filter\n",
            "==================================\n",
            "üîç Research Agent\n",
            "==================================\n",
            "‚úÖ Output:\n",
            " To accomplish this task, I'll use the Wikipedia tool to obtain the fundamental definitions and mathematical formulation of the Ensemble Kalman Filter.  After gathering information from Wikipedia, I'll summarize the findings and provide the current date for context. Let's begin by searching Wikipedia for this information.\n",
            "multi_tool_use.parallel ({_()\n",
            "tool_uses: {_\n",
            "{\n",
            "recipient_name: \"wikipedia_tool\",\n",
            "parameters: {_\n",
            "query: \"Ensemble Kalman Filter\"\n",
            "}_,\n",
            "}_,\n",
            "},\n",
            "}_);\n",
            "‚úÖ Output:\n",
            "To accomplish this task, I'll use the Wikipedia tool to obtain the fundamental definitions and mathematical formulation of the Ensemble Kalman Filter.  After gathering information from Wikipedia, I'll summarize the findings and provide the current date for context. Let's begin by searching Wikipedia for this information.\n",
            "multi_tool_use.parallel ({_()\n",
            "tool_uses: {_\n",
            "{\n",
            "recipient_name: \"wikipedia_tool\",\n",
            "parameters: {_\n",
            "query: \"Ensemble Kalman Filter\"\n",
            "}_,\n",
            "}_,\n",
            "},\n",
            "}_);\n",
            "\n",
            "üõ†Ô∏è Executing with agent: `research_agent` on task: Search arXiv and journal databases for key papers applying the ensemble Kalman filter to time series forecasting\n",
            "==================================\n",
            "üîç Research Agent\n",
            "==================================\n",
            "‚úÖ Output:\n",
            " To complete the task of searching for key papers applying the Ensemble Kalman Filter to time series forecasting and including the current date for context, I will use the arXiv tool to find academic papers. Let's proceed with this approach.\n",
            "I'll begin by querying the arXiv database for papers related to the application of the Ensemble Kalman Filter in time series forecasting.\n",
            "‚úÖ Output:\n",
            "To complete the task of searching for key papers applying the Ensemble Kalman Filter to time series forecasting and including the current date for context, I will use the arXiv tool to find academic papers. Let's proceed with this approach.\n",
            "I'll begin by querying the arXiv database for papers related to the application of the Ensemble Kalman Filter in time series forecasting.\n",
            "\n",
            "üõ†Ô∏è Executing with agent: `research_agent` on task: Compile summaries of seminal papers, including their objectives, methodologies, and performance results\n",
            "==================================\n",
            "üîç Research Agent\n",
            "==================================\n",
            "‚úÖ Output:\n",
            " To accomplish the task of compiling summaries of seminal papers related to the application of the Ensemble Kalman Filter (EnKF) in time series forecasting, I will utilize the arXiv tool to access relevant academic papers. I will search for papers that highlight the objectives, methodologies, and performance results regarding the use of EnKF for time series forecasting. Additionally, I'll include the current date, January 29, 2026, for context.\n",
            "\n",
            "Let's proceed by querying the arXiv database for papers related to the application of the Ensemble Kalman Filter in time series forecasting.\n",
            "Since I need to gather detailed information from several papers, I will simulate multiple arXiv queries in parallel. This approach allows me to compile comprehensive summaries from the pertinent research articles efficiently.\n",
            "‚úÖ Output:\n",
            "To accomplish the task of compiling summaries of seminal papers related to the application of the Ensemble Kalman Filter (EnKF) in time series forecasting, I will utilize the arXiv tool to access relevant academic papers. I will search for papers that highlight the objectives, methodologies, and performance results regarding the use of EnKF for time series forecasting. Additionally, I'll include the current date, January 29, 2026, for context.\n",
            "\n",
            "Let's proceed by querying the arXiv database for papers related to the application of the Ensemble Kalman Filter in time series forecasting.\n",
            "Since I need to gather detailed information from several papers, I will simulate multiple arXiv queries in parallel. This approach allows me to compile comprehensive summaries from the pertinent research articles efficiently.\n",
            "\n",
            "üõ†Ô∏è Executing with agent: `writer_agent` on task: Draft an introduction section covering background, motivation, and objectives of applying the ensemble Kalman filter to time series forecasting\n",
            "==================================\n",
            "‚úçÔ∏è Writer Agent\n",
            "==================================\n",
            "‚úÖ Output:\n",
            "# Introduction\n",
            "\n",
            "## Background\n",
            "\n",
            "Time series forecasting is a critical task in various scientific and industrial fields, ranging from meteorology and finance to control systems and bioinformatics. The primary goal of time series forecasting is to predict future values of a sequence based on past observed data, offering invaluable insights for decision-making and strategic planning. However, the inherent uncertainties and noise in real-world data present significant challenges that necessitate sophisticated forecasting methods.\n",
            "\n",
            "The Ensemble Kalman Filter (EnKF) is a prominent data assimilation algorithm originally developed for nonlinear systems with considerable model error and uncertainty, particularly within meteorological and oceanographic contexts. Introduced as an extension of the classic Kalman Filter, the EnKF utilizes a Monte Carlo approach to address the limitations posed by linear assumptions and Gaussian noise in highly complex systems. By employing a set of ensemble forecasts rather than a single deterministic model, the EnKF captures a diverse range of possible future states, thereby enhancing the reliability of its predictions.\n",
            "\n",
            "## Motivation\n",
            "\n",
            "The adaptation of the Ensemble Kalman Filter to time series forecasting emerges from a growing need for robust methods that can manage the dynamic and often chaotic nature of real-world time series data. Traditional statistical methods may falter under the weight of non-linearity and non-stationarity, common characteristics of time series data generated by complex systems. Meanwhile, the ability of the EnKF to iteratively update forecasts by integrating real-time observational data offers a promising avenue to mitigate these challenges.\n",
            "\n",
            "Moreover, the EnKF's capability of assimilating data through an ensemble of model states allows for a comprehensive representation of the uncertainty associated with forecasts. This makes it particularly well-suited to applications where capturing the uncertainty is as critical as obtaining precise predictions, such as in weather forecasting or risk assessment in finance.\n",
            "\n",
            "## Objectives\n",
            "\n",
            "The primary objective of applying the Ensemble Kalman Filter in time series forecasting is to enhance predictive accuracy and manage uncertainty more effectively than traditional approaches. By leveraging the adaptive and recursive properties of the EnKF, researchers and practitioners aim to refine forecasts continually as new data becomes available, achieving a balance between computational feasibility and forecasting precision.\n",
            "\n",
            "Key research endeavors focus on optimizing the implementation of the EnKF for time series data by fine-tuning model parameters, developing hybrid models that couple EnKF with other statistical or machine learning techniques, and exploring its applicability across diverse domains. The ongoing exploration into these areas seeks to unlock the full potential of the EnKF, solidifying its role as a cornerstone methodology in the arsenal of modern forecasting tools.\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "# Introduction\n",
              "\n",
              "## Background\n",
              "\n",
              "Time series forecasting is a critical task in various scientific and industrial fields, ranging from meteorology and finance to control systems and bioinformatics. The primary goal of time series forecasting is to predict future values of a sequence based on past observed data, offering invaluable insights for decision-making and strategic planning. However, the inherent uncertainties and noise in real-world data present significant challenges that necessitate sophisticated forecasting methods.\n",
              "\n",
              "The Ensemble Kalman Filter (EnKF) is a prominent data assimilation algorithm originally developed for nonlinear systems with considerable model error and uncertainty, particularly within meteorological and oceanographic contexts. Introduced as an extension of the classic Kalman Filter, the EnKF utilizes a Monte Carlo approach to address the limitations posed by linear assumptions and Gaussian noise in highly complex systems. By employing a set of ensemble forecasts rather than a single deterministic model, the EnKF captures a diverse range of possible future states, thereby enhancing the reliability of its predictions.\n",
              "\n",
              "## Motivation\n",
              "\n",
              "The adaptation of the Ensemble Kalman Filter to time series forecasting emerges from a growing need for robust methods that can manage the dynamic and often chaotic nature of real-world time series data. Traditional statistical methods may falter under the weight of non-linearity and non-stationarity, common characteristics of time series data generated by complex systems. Meanwhile, the ability of the EnKF to iteratively update forecasts by integrating real-time observational data offers a promising avenue to mitigate these challenges.\n",
              "\n",
              "Moreover, the EnKF's capability of assimilating data through an ensemble of model states allows for a comprehensive representation of the uncertainty associated with forecasts. This makes it particularly well-suited to applications where capturing the uncertainty is as critical as obtaining precise predictions, such as in weather forecasting or risk assessment in finance.\n",
              "\n",
              "## Objectives\n",
              "\n",
              "The primary objective of applying the Ensemble Kalman Filter in time series forecasting is to enhance predictive accuracy and manage uncertainty more effectively than traditional approaches. By leveraging the adaptive and recursive properties of the EnKF, researchers and practitioners aim to refine forecasts continually as new data becomes available, achieving a balance between computational feasibility and forecasting precision.\n",
              "\n",
              "Key research endeavors focus on optimizing the implementation of the EnKF for time series data by fine-tuning model parameters, developing hybrid models that couple EnKF with other statistical or machine learning techniques, and exploring its applicability across diverse domains. The ongoing exploration into these areas seeks to unlock the full potential of the EnKF, solidifying its role as a cornerstone methodology in the arsenal of modern forecasting tools."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# If you want to see the full workflow without limiting the number of steps. Set limit_steps to False\n",
        "# Keep in mind this could take more than 10 minutes to complete\n",
        "executor_history = executor_agent(\"The ensemble Kalman filter for time series forecasting\", limit_steps=True)\n",
        "\n",
        "md = executor_history[-1][-1].strip(\"`\")\n",
        "display(Markdown(md))"
      ]
    }
  ],
  "metadata": {
    "grader_version": "1",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}